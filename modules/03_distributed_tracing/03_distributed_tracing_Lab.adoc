:noaudio:
:scrollbar:
:data-uri:
:toc2:
:linkattrs:

= Distributed Tracing

== Monitoring with Prometheus and Grafana

Out of the box, you get additional monitoring via Prometheus and Grafana. 

https://prometheus.io/[Prometheus] is an open-source systems monitoring and alerting toolkit. Prometheus works well for recording any purely numeric time series. It fits both machine-centric monitoring as well as monitoring of highly dynamic service-oriented architectures. In a world of microservices, its support for multi-dimensional data collection and querying is a particular strength.

https://grafana.com/[Grafana] is an open platform for data analysis and visualization. Grafana lets you create graphs and dashboards based on data from various monitoring systems, and it specializes in the display and analysis of this data. It is lightweight, easy to install, and it looks beautiful. In particular, Grafana supports querying Prometheus.

=== Grafana Demo

[source,bash]
----
open "$(minishift openshift service grafana -u)/d/1/istio-dashboard?refresh=5s&orgId=1"
----

image:grafana1.png[alt text]

[source,bash]
----
open "$(minishift openshift service grafana -u)/d/UbsSZTDik/istio-workload-dashboard?refresh=5s&orgId=1"
----

to check the "Workload of the services"

image:grafana2.png[alt text]

[#custommetrics]
=== Prometheus Demo - Custom Metrics

Istio also allows you to specify custom metrics which can be seen inside of the Prometheus dashboard

[source,bash]
----
open "$(minishift openshift service prometheus -u)/graph?g0.range_input=5m&g0.expr=&g0.tab=0"
----

Add the custom metric and rule. First make sure you are in the "istio-tutorial" directory and then

[source,bash]
----
istioctl create -f istiofiles/recommendation_requestcount.yml -n istio-system
----

In the Prometheus dashboard, add the following

[source,bash]
----
istio_requests_total{destination_service="recommendation.tutorial.svc.cluster.local"}
----

and select `Execute`

image:prometheus_custom_metric.png[alt text]

Then run several requests through the system

[source,bash]
----
while true; do curl customer-tutorial.$(minishift ip).nip.io; sleep .5;  done
----

NOTE: You may have to refresh the browser for the Prometheus graph to update. And you may wish to make the interval 5m (5 minutes) as seen in the screenshot above.

[#tracing]
== Distrubted Tracing

Distributed Tracing involves propagating the tracing context from service to service, usually done by sending certain incoming HTTP headers downstream to outbound requests. For services embedding a http://opentracing.io/[OpenTracing] framework instrumentations such as https://github.com/opentracing-contrib/java-spring-cloud[opentracing-spring-cloud], this might be transparent. For services that are not embedding OpenTracing libraries, this context propagation needs to be done manually.

As OpenTracing is "just" an instrumentation library, a concrete tracer is required in order to actually capture the tracing data and report it to a remote server. Our `gateway` and `partner` services ship with http://jaegertracing.io/[Jaeger] as the concrete tracer. the Istio platform automatically sends collected tracing data to Jaeger, so that we are able to see a trace involving all three services, even if our `catalog` service is not aware of OpenTracing or Jaeger at all.

Our `gateway` and `partner` services are using the https://github.com/jaegertracing/jaeger-client-java/tree/master/jaeger-tracerresolver[`TracerResolver`] facility from OpenTracing, so that the concrete tracer can be loaded automatically without our code having a hard dependency on Jaeger. Given that the Jaeger tracer can be configured via environment variables, we don't need to do anything in order to get a properly configured Jaeger tracer ready and registered with OpenTracing. That said, there are cases where it's appropriate to manually configure a tracer. Refer to the Jaeger documentation for more information on how to do that.

In this lab, you use Jaeger to trace calls for our microservices. Jaeger is an implementation of the OpenTracing specification. Originally from Uber, Red Hat actively contributes to the project.

The Jaeger agent is deployed as a sidecar container next to the application component containers. The agent collects tracing data from the applications and transmits them to the Jaeger collector through port 14267.

The Jaeger sidecar runs the Jaeger agent, which acts as a proxy to the Jaeger collector. The agent is a daemon program that runs on every host and receives tracing information submitted by applications via Jaeger client libraries. The agent transmits this information to the Jaeger collector. The Jaeger tracer instance in the application transmits the tracing information to the agent using UDP.

=== Demo

Let's open the Jaeger console, select `gateway` from the list of services and click `Find Traces`

[source,bash]
----
minishift openshift service tracing --in-browser
----

image:jaegerUI.png[Trace as seen in Jaeger]

== Congratulations!

In this lab you learned how to install Kiali. You also learned how to use Kiali for monitoring your Istio service mesh.

Proceed to the next lab: link:03_distributed_tracing_Lab.html[*03 - Distributed Tracing*]

== References

* https://www.kiali.io/[Kiali]
* https://openshift.com[Red Hat OpenShift]
* https://learn.openshift.com/servicemesh[Learn Istio on OpenShift]
* https://istio.io[Istio Homepage]