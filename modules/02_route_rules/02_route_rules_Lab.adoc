:noaudio:
:scrollbar:
:data-uri:
:toc2:
:linkattrs:

= Dynamic Routing with Istio

== What is a Service Mesh?

As microservices-based applications become more prevalent, both the number of
and complexity of their interactions increases. Up until now much of the burden
of managing these complex microservices interactions has been placed on the
application developer, with different or non-existent support for microservice
concepts depending on language and framework.

The service mesh concept pushes this responsibility to the infrastructure, with
features for traffic management, distributed tracing and observability, policy
enforcement, and service/identity security, freeing the developer to focus on
business value. In this hands-on session you will learn how to apply some of
these features to a simple polyglot microservices application running on top of
OpenShift using Istio, an open platform to connect, manage, and secure
microservices.

== What is Istio?

https://istio.io/[Istio] is an open platform to connect, manage, and secure microservices. Istio
provides an easy way to create a network of deployed services with load
balancing, service-to-service authentication, monitoring, and more, without
requiring any changes in application code. OpenShift can automatically inject a
special sidecar proxy throughout your environment to enable Istio management for
your application. This proxy intercepts all network communication between your
microservices microservices, and is configured and managed using Istioâ€™s control
plane functionality -- not your application code!

image::images/02_service_mesh_architecture.png[Service Mesh Architecture]

== Lab Overview

There are three microservices in this lab and they are chained together in the following sequence:

`gateway -> partner -> catalog`

In this lab you'll dynamically alter routing between the services using Istio.

== Goals

In this lab, you will learn how to:

* Inject sidecar proxies into applications which form a service mesh
* Configure a service mesh to dynamically route and shape traffic to and from services

== Deploy Catalog service version 2 (`v2`)

We can experiment with Istio routing rules by deploying a second version of the catalog
service.

. Edit Java source code to show v2 message
+
----
cd ~/lab/rhte-msa-and-service-mesh/catalog/java/vertx

vi src/main/java/com/redhat/developer/demos/catalog/CatalogVerticle.java
----

. In the file `CatalogVerticle.java`, update this line to say `v2`
+
----
private static final String RESPONSE_STRING_FORMAT = "catalog v2 from '%s': %d\n";
----

. Save the file and exit vi.

. Build the service with the following commands:
+
----
mvn clean package

sudo docker build -t example/catalog:v2 .
----
+
NOTE: The "v2" tag during the Docker build is significant.

. Deploy Catalog service version 2 
+
----
oc apply -f <(istioctl kube-inject -f ../../kubernetes/Deployment-v2.yml) -n $OCP_TUTORIAL_PROJECT
----
+
* This second deployment file `Deployment-v2.yml` will label the service correctly.

. You can see both versions of the `catalog` pods running with the following command:
+
----
oc get pods -l app=catalog -w
----
+
* For the `catalog-v2` service, wait until the Ready column has `2/2` pods and the Status column has `Running`. 

* You should see:
+
----
NAME                          READY     STATUS    RESTARTS   AGE
catalog-v1-6b576ffcf8-g6b48   2/2       Running   0          31m
catalog-v2-7764964564-hj8xl   2/2       Running   0          49s
----
+

* To exit, press Ctrl+C.

* By default, Istio will round-robin incoming requests to the `catalog` Service
so that both `v1` and `v2` pods get equal amounts of traffic.

. Make sure your environment variable for $GATEWAY_URL is still set.
+
----
echo $GATEWAY_URL
----

. Test the gateway service
+
----
curl $GATEWAY_URL
----

* You will likely see:
+
----
gateway => partner => catalog v1 from '6b576ffcf8-g6b48': 2
----
+
* Where `6b576ffcf8-g6b48` is the pod running `v1` and the `2` is the number of times you hit the endpoint.

. Make another request to the gateway service
+
----
curl $GATEWAY_URL
----

* You will likely see:
+
----
gateway => partner => catalog v2 from '7764964564-hj8xl': 1
----
+
* Where `7764964564-hj8xl` is the pod running `v2` and the `1` is basically the number of times you hit the endpoint.

* By default you get round-robin load-balancing when there is more than one Pod behind a Service

. Send severals to the gateway service. 
+
----
~/lab/rhte-msa-and-service-mesh/scripts/run.sh
----
+
* The `run.sh` script will loop and send 10 requests to the `gateway` service.

* You should see:
+
----
gateway => partner => catalog v1 from '6b576ffcf8-g6b48': 4
gateway => partner => catalog v2 from '7764964564-hj8xl': 3
gateway => partner => catalog v1 from '6b576ffcf8-g6b48': 5
gateway => partner => catalog v2 from '7764964564-hj8xl': 4
gateway => partner => catalog v1 from '6b576ffcf8-g6b48': 6
gateway => partner => catalog v2 from '7764964564-hj8xl': 5
gateway => partner => catalog v1 from '6b576ffcf8-g6b48': 7
gateway => partner => catalog v2 from '7764964564-hj8xl': 6
gateway => partner => catalog v1 from '6b576ffcf8-g6b48': 8
gateway => partner => catalog v2 from '7764964564-hj8xl': 7
----
+
* Approximately half of the requests above go to `v1` and the other half to `v2`.

* The default Kubernetes/OpenShift behavior is to round-robin load-balance across all
available pods behind a single Service. 

. Scale up the number of pods for the `catalog-v2` pod:
+
----
oc scale --replicas=2 deployment/catalog-v2
----

. Monitor the scaling up of the new pod
+
----
oc get pods -l app=catalog -w
----
+
* Wait until you see two entries for the `catalog-v2` service. Also wait until the Ready column has `2/2` pods and the Status column has `Running`. 

* You should see:
+
----
NAME                          READY     STATUS    RESTARTS   AGE
catalog-v1-6b576ffcf8-g6b48   2/2       Running   0          31m
catalog-v2-7764964564-hj8xl   2/2       Running   0          10m
catalog-v2-7764964564-d8qwp   2/2       Running   0          49s
----
+

* To exit, press Ctrl+C.

. Now let's send in 10 requests
+
----
~/lab/rhte-msa-and-service-mesh/scripts/run.sh
----

* You should see:
+
----
gateway => partner => catalog v2 from '7764964564-hj8xl': 8
gateway => partner => catalog v2 from '7764964564-d8qwp': 1
gateway => partner => catalog v1 from '6b576ffcf8-g6b48': 9
gateway => partner => catalog v2 from '7764964564-hj8xl': 9
gateway => partner => catalog v2 from '7764964564-d8qwp': 2
gateway => partner => catalog v1 from '6b576ffcf8-g6b48': 10
gateway => partner => catalog v2 from '7764964564-hj8xl': 10
gateway => partner => catalog v2 from '7764964564-d8qwp': 3
gateway => partner => catalog v1 from '6b576ffcf8-g6b48': 11
gateway => partner => catalog v2 from '7764964564-hj8xl': 11
----
+
* Notice that *double* the number of requests are sent to `v2` than for `v1`:

. Scale back to a single pod for the `catalog-v2` deployment:
+
----
oc scale --replicas=1 deployment/catalog-v2
----

. Run the test again and confirm that the requests are split evenly between `v1` and `v2`.

== Send all traffic to `catalog:v2`

_Route rules_ control how requests are routed within an Istio service mesh.

Requests can be routed based on the source and destination, HTTP header fields, and weights associated with individual service versions. For example, a route rule could route requests to different versions of a service.

In addition to the usual OpenShift object types like `BuildConfig`, `DeploymentConfig`,
`Service` and `Route`, you also have new object types installed as part of Istio like `RouteRule`. Adding these objects to the running OpenShift cluster is how you configure routing rules for Istio.

* `DestinationRule` defines policies that apply to traffic intended for a service after routing has occurred. These rules specify configuration for load balancing, connection pool size from the sidecar, and outlier detection settings to detect and evict unhealthy hosts from the load balancing pool. 
* A `VirtualService` defines a set of traffic routing rules to apply when a host is addressed. Each routing rule defines matching criteria for traffic of a specific protocol. If the traffic is matched, then it is sent to a named destination service (or subset/version of it) defined in the registry. The source of traffic can also be matched in a routing rule. This allows routing to be customized for specific client contexts.

. View a simple load balancing policy for the `catalog` service 

. Below is an istio configuration file to route all traffic to `v2`. File name: `istiofiles/virtual-service-catalog-v2.yml`.
+
----
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: catalog
spec:
  hosts:
  - catalog
  http:
  - route:
    - destination:
        host: catalog <1>
        subset: version-v2 <2>
      weight: 100 <3>
----

<1> Apply this for the destination `catalog`
<2> Apply to `v2` of `catalog`
<3> Route 100% of traffic to `catalog v2`

* This definition allows you to configure a percentage of traffic and direct it to a specific version of the `catalog` service. In this case, 100% of traffic for the catalog service will always go to pods matching the labels version: `v2`. The selection of pods here is very similar to the Kubernetes selector model for matching based on labels. So, any service within the service mesh that tries to communicate with the `catalog` service will always be routed to `v2` of the `catalog` service.

. Route all traffic to `v2` using the configuration file:
+
----
cd ~/lab/rhte-msa-and-service-mesh

oc create -f istiofiles/destination-rule-catalog-v1-v2.yml -n $OCP_TUTORIAL_PROJECT --as=system:admin
oc create -f istiofiles/virtual-service-catalog-v2.yml -n $OCP_TUTORIAL_PROJECT --as=system:admin
----
+
NOTE: Your OCP user has been provided with the ability to impersonate the system:admin user so as to execute this command. Please use this capability with caution. In a real-world setting, you would have coordinated with a team-member who does with cluster admin rights to execute this command for you. 

. Test the `gateway` service again - all requests should end up talking to
`catalog:v2`:
+
----
scripts/run.sh
----
+
* You should only see `v2` being returned.
+
----
gateway => partner => catalog v2 from '7764964564-hj8xl': 17
gateway => partner => catalog v2 from '7764964564-hj8xl': 18
gateway => partner => catalog v2 from '7764964564-hj8xl': 19
gateway => partner => catalog v2 from '7764964564-hj8xl': 20
gateway => partner => catalog v2 from '7764964564-hj8xl': 21
gateway => partner => catalog v2 from '7764964564-hj8xl': 22
gateway => partner => catalog v2 from '7764964564-hj8xl': 23
gateway => partner => catalog v2 from '7764964564-hj8xl': 24
gateway => partner => catalog v2 from '7764964564-hj8xl': 25
gateway => partner => catalog v2 from '7764964564-hj8xl': 26
----

== Send all traffic to `catalog:v1`

* Now let's switch this over to v1. We'll use the following configuration. File: istiofiles/virtual-service-catalog-v1.yml
+
----
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: catalog
spec:
  hosts:
  - catalog
  http:
  - route:
    - destination:
        host: catalog <1>
        subset: version-v1 <2>
      weight: 100 <3>
---

<1> Apply this for the destination `catalog`
<2> Apply to `v2` of `catalog`
<3> Route 100% of traffic to `catalog v2`

. Now let's move everyone to catalog service `v1`:
+
----
oc replace -f istiofiles/virtual-service-catalog-v1.yml -n $OCP_TUTORIAL_PROJECT --as=system:admin
----
+
NOTE: We use `oc replace` instead of `oc create` since we are overlaying the previous rule

. Now let's send in 10 requests:
+
----
scripts/run.sh
----
+
* You should see all requests now to go `v1`:
+
----
gateway => partner => catalog v1 from '6b576ffcf8-g6b48': 17
gateway => partner => catalog v1 from '6b576ffcf8-g6b48': 18
gateway => partner => catalog v1 from '6b576ffcf8-g6b48': 19
gateway => partner => catalog v1 from '6b576ffcf8-g6b48': 20
gateway => partner => catalog v1 from '6b576ffcf8-g6b48': 21
gateway => partner => catalog v1 from '6b576ffcf8-g6b48': 22
gateway => partner => catalog v1 from '6b576ffcf8-g6b48': 23
gateway => partner => catalog v1 from '6b576ffcf8-g6b48': 24
gateway => partner => catalog v1 from '6b576ffcf8-g6b48': 25
gateway => partner => catalog v1 from '6b576ffcf8-g6b48': 26
----

. Remove the route rules to get back to default round-robin distribution
of requests.
+
----
oc delete -f istiofiles/virtual-service-catalog-v1.yml -n $OCP_TUTORIAL_PROJECT --as=system:admin
----

. Now let's send in 10 requests:
+
----
scripts/run.sh
----
+
* Traffic should be equally split once again between `v1` and `v2`.

== Use a Canary Deployment to slowly rollout `v2`

Canary Deployment scenario: push v2 into the cluster but slowly send end-user traffic to it, if you continue to see success, continue shifting more traffic over time.

. Create the virtualservice that will send 75% of requests to v1 and 25% to v2:
+
----
oc create -f istiofiles/virtual-service-catalog-v1_and_v2_75_25.yml -n $OCP_TUTORIAL_PROJECT --as=system:admin
----

. And issue 10 requests:
+
----
scripts/run.sh
----
+ 
* Now you should see 7 or 8 requests (~75%) going to `v1`. You should see 2 or 3 requests (~25%) going to `v2`. This process can be continued (and automated), slowly migrating
traffic over to the new version as it proves its worth in production over time.

== Clean Up

. Remove the route rules before moving on:
+
----
scripts/clean.sh $OCP_TUTORIAL_PROJECT
----

== Congratulations!

In this lab you learned how to deploy microservices to form a _service mesh_ using Istio.
You also learned how to do traffic shaping and routing using _Route Rules_ which instruct
the Istio sidecar proxies to distribute traffic according to specified policy.

Proceed to the next lab: link:03_circuit_breaker_Lab.html[*03 - Circuit Breaker*]

== References

* https://openshift.com[Red Hat OpenShift]
* https://learn.openshift.com/servicemesh[Learn Istio on OpenShift]
* https://istio.io[Istio Homepage]